{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collect Basic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve CryptoCurrency Market Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from functools import reduce\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "CRYPTO = False\n",
    "\n",
    "# Crypto Details\n",
    "cryptoProducts = [\"ETH-USD\", \"USDT-USD\", \"BTC-USD\"]\n",
    "availableGranularities = dict(zip([\"1M\", \"5M\", \"15M\", \"1H\", \"6H\", \"1D\"], [60, 300, 900, 3600, 21600, 86400]))\n",
    "\n",
    "# Stock Details\n",
    "dowTickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"TSLA\", \"AMZN\", \"NVDA\"]  \n",
    "sse50Tickers = [\"600519.SS\", \"601318.SS\", \"601857.SS\", \"600036.SS\", \"600016.SS\", \"600000.SS\"]  \n",
    "sensexTickers = [\"RELIANCE.BO\", \"TCS.BO\", \"INFY.BO\", \"ICICIBANK.BO\", \"SBIN.BO\", \"HINDUNILVR.BO\"] \n",
    "ftse100Tickers = [\"HSBA.L\", \"BP.L\", \"GSK.L\", \"SHEL.L\", \"BATS.L\", \"ULVR.L\"]  \n",
    "period = \"1D\"\n",
    "indexProducts = dowTickers + sse50Tickers + sensexTickers + ftse100Tickers\n",
    "productIds = indexProducts\n",
    "\n",
    "if CRYPTO:\n",
    "    productIds = cryptoProducts\n",
    "    period = \"6H\"\n",
    "    granularity = availableGranularities[period]\n",
    "    API_THRESHOLD = 300 #Can only get 300 periods at a time from API\n",
    "    PERIODS_WANTED = 2500\n",
    "\n",
    "# not a chance\n",
    "def retrieveCryptoData(productID, granularity, daysBack, endTime):\n",
    "    API_URL = f\"https://api.exchange.coinbase.com/products/{productID}/candles\"\n",
    "    daysBackDaysAgo = timedelta(days=daysBack)\n",
    "    startTime = datetime.fromisoformat(endTime) - (granularity/86400) * daysBackDaysAgo\n",
    "\n",
    "    # Convert to isoformat\n",
    "    startTime = startTime.isoformat()\n",
    "\n",
    "    # Set Request Parameters\n",
    "    parameters = {\n",
    "        \"start\" : startTime,\n",
    "        \"end\" : endTime,\n",
    "        \"granularity\" : str(granularity)\n",
    "    }\n",
    "\n",
    "    # Actually get data\n",
    "    data = requests.get(API_URL, params = parameters, headers = {\"content-type\":\"application/json\"})\n",
    "    df = pd.DataFrame(data.json(), columns=[\"time\", \"low\", \"high\", \"open\", \"close\", \"volume\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "def retrieveIndexData(ticker):\n",
    "    # Define date range\n",
    "    startDate = \"2009-01-01\"\n",
    "    endDate = \"2020-08-05\"\n",
    "\n",
    "    ohlcData = {}\n",
    "    try:\n",
    "        stockData = yf.download(ticker, start=startDate, end=endDate)\n",
    "        ohlcData[ticker] = stockData[[\"Low\", \"High\", \"Open\", \"Close\", \"Volume\"]]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "\n",
    "    dfOhlc = pd.concat(ohlcData, axis=1)\n",
    "    return dfOhlc\n",
    "\n",
    "\n",
    "dataframes = dict()\n",
    "RETRIEVE_DATA = False\n",
    "\n",
    "if RETRIEVE_DATA:\n",
    "    for productId in productIds:\n",
    "        if CRYPTO:\n",
    "            # Fetch PERIODS_WANTED periods of data\n",
    "            end = (datetime.now()).isoformat()\n",
    "            for batch in range(PERIODS_WANTED // API_THRESHOLD  + 1):\n",
    "                amountToFetch = PERIODS_WANTED % API_THRESHOLD if batch == PERIODS_WANTED // API_THRESHOLD else API_THRESHOLD\n",
    "                tempDF = retrieveCryptoData(productId, granularity, amountToFetch, end)\n",
    "                timeInSeconds = (tempDF['time'].values)[-1]\n",
    "                dt = datetime.fromtimestamp(timeInSeconds - granularity)\n",
    "                end = dt.isoformat() + 'Z'\n",
    "                value = dataframes.get(productId)\n",
    "                if productId not in dataframes:\n",
    "                    dataframes[productId] = tempDF[::-1]\n",
    "                else:\n",
    "                    dataframes[productId] = pd.concat([tempDF[::-1], dataframes[productId]])\n",
    "        else:\n",
    "            dataframe = retrieveIndexData(ticker=productId)\n",
    "            columnNames = [value[1].lower() for value in list(dataframe.columns.values)]\n",
    "            dataframe.columns = columnNames\n",
    "            dataframes[productId] = dataframe\n",
    "   \n",
    "# Required for index data that pull stock data from different exchanges\n",
    "def commonaliseData(data):\n",
    "    commonDates = reduce(lambda x, y: x.intersection(y), [df.index for df in data.values()])\n",
    "    for ticker, df in data.items():\n",
    "        data[ticker] = df.reindex(commonDates)\n",
    "        data[ticker][\"Times\"] = commonDates\n",
    "    data = {ticker: df.dropna() for ticker, df in data.items()}\n",
    "    PERIODS_WANTED = data.get(indexProducts[0]).shape[0]\n",
    "    return data\n",
    "\n",
    "if not CRYPTO and RETRIEVE_DATA:\n",
    "    dataframes = commonaliseData(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CORRECT_ORDER = False\n",
    "\n",
    "if TEST_CORRECT_ORDER:\n",
    "    testTime = dataframes[productIds[0]]['time'].values\n",
    "    testTime -= testTime[0]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(testTime, color=\"blue\")\n",
    "    plt.title(f\"Test Correct Order\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Augment State Space (add indicators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicator 1: Exponential Moving Average ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def EMA(array, N):\n",
    "    \"\"\"\n",
    "    EMA_t = (Price_t * α) + (EMA_(t-1) * (1 - α))\n",
    "    where:\n",
    "    EMA_t = Exponential Moving Average at time t\n",
    "    Price_t = Price at time t\n",
    "    α (alpha) = Smoothing factor, calculated as 2 / (N + 1)\n",
    "    N = Number of periods\n",
    "    \"\"\"\n",
    "    smoothingParameter = 2/(N + 1)\n",
    "    finalArray = [array[0]]\n",
    "    for i in range(1, len(array)):\n",
    "        finalArray.append(array[i] * smoothingParameter + finalArray[i-1] * (1 - smoothingParameter))\n",
    "    return np.array(finalArray)\n",
    "\n",
    "# expMA = EMA(closingPrices, t)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(expMA, label=f\"Exponential Moving Average: T={t}\", color=\"red\")\n",
    "# plt.plot(closingPrices, label=\"Actual Closing Prices\", color=\"blue\")\n",
    "# plt.title(f\"Price Data\")\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.ylabel(\"Price\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicator 2: Momemtum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Momentum(array):\n",
    "    # Percentage Change in Price/Time\n",
    "    momentumArray = [(array[i] - array[i-1]) /array[i-1] for i in range(1, len(array))]\n",
    "    momentumArray.insert(0, np.nan)\n",
    "    return np.array(momentumArray)\n",
    "\n",
    "# momentum = Momentum(closingPrices)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(momentum*100, color=\"green\")\n",
    "# plt.title(f\"Momentum Data (as %)\")\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.ylabel(\"Momentum\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicator 3: Average True Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trueRange(high, low, close):\n",
    "    # TR = Max[(H - L), |H - C|, |L - C|\n",
    "    closing = np.insert(close, 0, np.nan, axis=0)[:len(close)]\n",
    "    return np.maximum(high - low, np.abs(high - closing), np.abs(low - closing))\n",
    "\n",
    "def averageTrueRange(high, low, close, n=14):\n",
    "    trueRanges = trueRange(high, low, close)\n",
    "    atr = np.empty_like(trueRanges)\n",
    "    atr[:n] = np.nan  # First n values are NaN\n",
    "    atr[n-1] = np.mean(trueRanges[:n])  # Initial ATR value (simple average of the first n TRs)\n",
    "    for i in range(n+1, len(trueRanges)):\n",
    "        atr[i] = (atr[i-1] * (n - 1) + trueRanges[i]) / n\n",
    "    return atr\n",
    "\n",
    "# aTRIndicator = averageTrueRange(highs, lows, closingPrices)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(aTRIndicator, color=\"Brown\")\n",
    "# plt.title(f\"Average True Range over Time\")\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.ylabel(\"Average True Range\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicator 4: Commodity Channel Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commodityChannelIndex(high, low, close, n=20):\n",
    "    # (Typical Price - 20_Day Moving Average) / .015 x Mean Deviation\n",
    "    typicalPrices = (high + low + close) / 3\n",
    "    \n",
    "    movingAverage = np.full_like(high, np.nan)\n",
    "    meanDeviation = np.full_like(high, np.nan)\n",
    "    \n",
    "    for i in range(n, len(typicalPrices)):\n",
    "        movingAverage[i] = np.mean(typicalPrices[i-n:i])\n",
    "        meanDeviation[i] = np.mean(np.abs(typicalPrices[i-n:i] - movingAverage[i]))\n",
    "    \n",
    "    cci = np.full_like(high, np.nan, dtype=np.float64)\n",
    "\n",
    "    numerator = typicalPrices[n:] - movingAverage[n:]\n",
    "    denominator = 0.015 * meanDeviation[n:]\n",
    "    result = np.empty_like(numerator)\n",
    "\n",
    "    np.divide(numerator, denominator, out=result, where=(denominator != 0))\n",
    "    # a little hacky...\n",
    "    result[denominator == 0] = 0\n",
    "\n",
    "    cci[n:] = result\n",
    "    return cci\n",
    "\n",
    "# # CCI = commodityChannelIndex(highs, lows, closingPrices)\n",
    "# # plt.figure(figsize=(10, 6))\n",
    "# # plt.plot(CCI, color=\"black\")\n",
    "# # plt.title(f\"Commodity Channel Index over Time\")\n",
    "# # plt.xlabel(\"Time\")\n",
    "# # plt.ylabel(\"Commodity Channel Index\")\n",
    "# # plt.legend()\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicator 5: MACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MACD = 12-day EMA - 26-day EMA\n",
    "Signal Line = 9-day EMA of MACD\n",
    "MACD Histogram = MACD - Signal Line\n",
    "where EMA stands for Exponential Moving Average\n",
    "\"\"\"\n",
    "\n",
    "def MACD(array):\n",
    "    return EMA(array, 12) - EMA(array, 26)\n",
    "\n",
    "def MACDSignal(array):\n",
    "    return EMA(MACD(array), 9)\n",
    "\n",
    "MACDHistogram = lambda x : MACD(x) - MACDSignal(x)\n",
    "\n",
    "# mACD = MACD(closingPrices)\n",
    "# signalLine = MACDSignal(closingPrices)\n",
    "# macdHistogram = MACDHistogram(mACD, signalLine)\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(mACD, color=\"blue\", label = \"MACD Line\")\n",
    "# plt.plot(signalLine, color = \"red\", label = \"Signal Line\")\n",
    "# plt.plot(macdHistogram, color = \"black\", label = \"Histogram\")\n",
    "# plt.title(f\"Moving Average Convergence-Divergence\")\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.ylabel(\"MACD\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Collate All Features Into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CCI_T, ATR_T = 20, 14\n",
    "if RETRIEVE_DATA:\n",
    "    for product in productIds:\n",
    "        df = dataframes[product]\n",
    "        close = df[\"close\"].values\n",
    "        highs = df[\"high\"].values\n",
    "        lows = df[\"low\"].values\n",
    "        df['E_M_A'] = EMA(close, N=30)\n",
    "        df['Momentum'] = Momentum(close)\n",
    "        df['Av_True_Range'] = averageTrueRange(highs, lows, close, 14)\n",
    "        df['CCI'] = commodityChannelIndex(highs, lows, close, 20)\n",
    "        df['MACDHist'] = MACDHistogram(close)\n",
    "        df[\"Return\"] = df[\"close\"].pct_change().fillna(0)\n",
    "        # Reset Indexes\n",
    "        df = df.drop(columns=['open', 'high', 'volume', 'low'])\n",
    "        df = df.iloc[max(ATR_T, CCI_T):]\n",
    "        df = df.reset_index(drop=True)\n",
    "        dataframes[product] = df\n",
    "        if not os.path.exists(\"CSVs/\"):\n",
    "            os.makedirs(\"CSVs/\")\n",
    "        df.to_csv(f\"CSVs/{product}_{period}_periods.csv\", sep='\\t')\n",
    "else:\n",
    "    for productId in productIds:\n",
    "        df = pd.read_csv(f\"CSVs/{productId}_{period}_periods.csv\", sep='\\t')\n",
    "        dataframes[productId] = df.iloc[:, 1:]  # Drops the first column\n",
    "\n",
    "times = None\n",
    "if not CRYPTO:\n",
    "    for product in productIds:\n",
    "        df = dataframes[product]\n",
    "        times = df['Times']\n",
    "        dataframes[product] = df.drop('Times', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Environment and Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse50BuyAndHold =  np.array([0] + [1/len(sse50Tickers) if i in sse50Tickers else 0 for i in productIds])\n",
    "sensexBuyAndHold = np.array([0] + [1/len(sensexTickers) if i in sensexTickers else 0 for i in productIds])\n",
    "ftse100BuyAndHold = np.array([0] + [1/len(ftse100Tickers) if i in ftse100Tickers else 0 for i in productIds])\n",
    "dowBuyAndHold = np.array([0] + [1/len(dowTickers) if i in dowTickers else 0 for i in productIds])\n",
    "buyAndHoldAll = np.array([0] + [1/(len(productIds)) for i in productIds])\n",
    "\n",
    "#Non\n",
    "NON_RL_COMPARISON_STRATEGIES = {\n",
    "    \"SSEBuyAndHold\" : sse50BuyAndHold,\n",
    "    \"SENSEXBuyAndHold\" : sensexBuyAndHold,\n",
    "    \"FTSEBuyAndHold\" : ftse100BuyAndHold,\n",
    "    \"DOWBuyAndHold\" : dowBuyAndHold,\n",
    "    \"BuyAndHoldAll\" : buyAndHoldAll\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters (most of them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "NUMBER_OF_ASSETS = len(productIds)\n",
    "NUMBER_OF_FEATURES = 1 + (len((list(dataframes.values())[0]).columns)) * len(productIds)\n",
    "if not CRYPTO:\n",
    "    PERIODS_WANTED = list(dataframes.values())[0].shape[0]\n",
    "EXPERIMENTS = 2\n",
    "TRAINING_PERIODS = int(PERIODS_WANTED / EXPERIMENTS) # will probably have to change this to times\n",
    "TIME_WINDOW = 30\n",
    "LEARNING_FREQUENCIES = (TRAINING_PERIODS / np.array([10, 20, 30, 40, 50])).astype(int)\n",
    "START_CASH = 1000000\n",
    "LSTMHIDDENSIZE = 128\n",
    "AGENT_RISK_AVERSIONS = np.array([0.25, 0.5, 1, 1.5, 2]) #i know, this probably shouldn't go here\n",
    "STRATEGIES = [\"PPOLSTM\", \"RANDOM\"]#, \"TD3\"] #td3 requires debugging - dont run\n",
    "FINAL_STRATEGIES = STRATEGIES + [\"SSEBuyAndHold\", \"SENSEXBuyAndHold\", \"FTSEBuyAndHold\", \"DOWBuyAndHold\", \"BuyAndHoldAll\"]\n",
    "REPEATS = 10\n",
    "LSTMOUTPUTSIZES = [64, 128, 256, 512, 1024]\n",
    "STARTS = [0] + [i *  TRAINING_PERIODS + -TIME_WINDOW for i in range(1, EXPERIMENTS)]\n",
    "PORTFOLIO_TRAJECTORIES = []\n",
    "REWARD_FUNCTIONS = [\"Standard Logarithmic Returns\" ,\"Differential Sharpe Ratio_0.01\", \"Differential Sharpe Ratio_0.05\", \"Differential Sharpe Ratio_0.1\", \"CVaR\"]\n",
    "NUMBER_OF_PARALLEL_ENVIRONMENTS = [0, 1, 2, 3, 4]\n",
    "LEARNING_RATES = [1e-4, 3e-4, 5e-4, 7e-4]\n",
    "RL_STRATS = [\"PPOLSTM\"]#, \"TD3\"]\n",
    "averagePerformance = defaultdict(list)\n",
    "allResults = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thing being tested\n",
    "TESTING = {\n",
    "    \"RISK AVERSION\" : False,\n",
    "    \"LSTM OUTPUT SIZE\" : False,\n",
    "    \"REWARD FUNCTION\" : False,\n",
    "    \"LEARNING FREQUENCY\": False, \n",
    "    \"PARALLEL ENVIRONMENTS\" : False, \n",
    "    \"LEARNING RATE\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some helper functions for metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import tabulate_neatly\n",
    "\n",
    "def printConfiguration(agent=None, freq=None):\n",
    "    table = [[\"LSTM Hidden Size\", \"LSTM Output Size\", \"Learning Frequency\", \"Agent Risk Aversion\"]]\n",
    "    table.append([LSTMHIDDENSIZE, agent.state_n, freq, agent.riskAversion])\n",
    "    tabulate_neatly(table, headers=\"firstrow\", title=f\"Configuration:\")\n",
    "\n",
    "def plotAllocations(allocations, title=None):\n",
    "    categories = ['Cash'] + productIds\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.bar(categories, allocations)\n",
    "    plt.xlabel('Allocations')\n",
    "    plt.tick_params(axis='x', labelsize=6)\n",
    "    plt.ylabel('Proportion Allocated')\n",
    "    plt.title('Allocations' if title == None else title)\n",
    "    plt.show()\n",
    "\n",
    "def generateConfigLabel(strategy, agent, episode, rewardFunction, freq, parr, lr):\n",
    "    firstTag = f\"Strategy-{strategy}\" \n",
    "    lastTag = f\"Experiment {episode + 1}\"\n",
    "    innerTag = None\n",
    "    boole = (strategy not in NON_RL_COMPARISON_STRATEGIES.keys() and strategy != \"RANDOM\")\n",
    "    if TESTING[\"RISK AVERSION\"]:\n",
    "        innerTag = (f\"Risk Aversion-{agent.riskAversion}\" if boole else \"\")\n",
    "    elif TESTING[\"LSTM OUTPUT SIZE\"]:\n",
    "        innerTag = (f\"LSTM Output Size-{agent.state_n}\" if boole else \"\")\n",
    "    elif TESTING[\"REWARD FUNCTION\"]:  \n",
    "        innerTag = (f\"Reward Function-{rewardFunction}\" if boole else \"\")\n",
    "    elif TESTING[\"LEARNING FREQUENCY\"]:  \n",
    "        innerTag = (f\"Learning Frequency-{freq}\" if boole else \"\")\n",
    "    elif TESTING[\"PARALLEL ENVIRONMENTS\"]:  \n",
    "        innerTag = (f\"Parallel Environments-{parr}\" if boole else \"\")\n",
    "    elif TESTING[\"LEARNING RATE\"]:  \n",
    "        innerTag = (f\"Learning Rate-{lr}\" if boole else \"\")\n",
    "    \n",
    "    if any(TESTING.values()) and boole:\n",
    "        firstTag, innerTag = innerTag, firstTag\n",
    "    return firstTag + \" | \" +  innerTag + \" | \" + lastTag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PPO import PPOAgent\n",
    "from TD3 import TD3Agent\n",
    "\n",
    "def generateAgent(strat, lstmOutputSize, riskAversion, lr):\n",
    "    if strat == \"TD3\":\n",
    "        return TD3Agent(\n",
    "                state_n=lstmOutputSize,\n",
    "                actions_n=len(productIds) + 1,\n",
    "                alpha=lr,\n",
    "                beta=0.001,\n",
    "                gamma=0.99,\n",
    "                tau=0.005,\n",
    "                lstmHiddenSize = LSTMHIDDENSIZE,\n",
    "                actor_noise=0.01,\n",
    "                target_noise=0.01,\n",
    "                env=None,\n",
    "                batch_size=128,\n",
    "                fc1_n=512,\n",
    "                fc2_n=384,\n",
    "                riskAversion=riskAversion,\n",
    "            )\n",
    "    elif strat == \"PPOLSTM\":\n",
    "        return PPOAgent( \n",
    "                        state_n=lstmOutputSize, \n",
    "                        actions_n=len(productIds) + 1,\n",
    "                        alpha=lr,\n",
    "                        policyClip = 0.2,\n",
    "                        gamma=0.99,\n",
    "                        lstmHiddenSize=LSTMHIDDENSIZE,\n",
    "                        actor_noise=0,\n",
    "                        batch_size=512,\n",
    "                        fc1_n=128,\n",
    "                        fc2_n=128,\n",
    "                        gaeLambda=0.98,\n",
    "                        epochs=10,\n",
    "                        riskAversion=riskAversion,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PPO import PPOAgent\n",
    "from TD3 import TD3Agent\n",
    "from LstmFeatureExtractor import LstmFeatureExtractor\n",
    "from TimeSeriesEnvironment import TimeSeriesEnvironment\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "def initializeEnvironments(start, parr, rewardFunction, riskAversion, strategy):\n",
    "    primaryEnvironment = TimeSeriesEnvironment(dataframes, start, TIME_WINDOW, TRAINING_PERIODS, START_CASH, riskAversion, 2.5e-4)\n",
    "    parallelEnvironments = [\n",
    "        TimeSeriesEnvironment(dataframes, start, TIME_WINDOW, TRAINING_PERIODS, START_CASH, riskAversion, 2.5e-4)\n",
    "        for _ in range(parr)\n",
    "    ]\n",
    "    primaryEnvironment.TD3 = strategy == \"TD3\"\n",
    "    for parallel in parallelEnvironments:\n",
    "        parallel.TD3 = strategy == \"TD3\"\n",
    "    if strategy == \"RANDOM\":\n",
    "            primaryEnvironment.maxAllocationChange = 1\n",
    "            for env in parallelEnvironments:\n",
    "                env.maxAllocationChange = 1\n",
    "    if \"Differential\" in rewardFunction:\n",
    "        decay = float(rewardFunction.split(\"_\")[1])\n",
    "        primaryEnvironment.decayRate = decay\n",
    "        for env in parallelEnvironments:\n",
    "            env.decayRate = decay\n",
    "            env.maxAllocationChange = 1\n",
    "    return primaryEnvironment, parallelEnvironments\n",
    "\n",
    "def storeExperiences(agent, data, outputs, reward, done, strategy, parr, action, prob, val, next):\n",
    "        if strategy == \"PPOLSTM\":\n",
    "            agent.store(data, action, prob, val, reward, done)\n",
    "            for i in range(parr):\n",
    "                agent.store(\n",
    "                    data,\n",
    "                    outputs[\"actions\"][i],\n",
    "                    outputs[\"probabilities\"][i],\n",
    "                    outputs[\"valuations\"][i].squeeze(),\n",
    "                    float(outputs[\"rewards\"][i]),\n",
    "                    bool(outputs[\"dones\"][i])\n",
    "                )\n",
    "        elif strategy == \"TD3\":\n",
    "            agent.store(\n",
    "                data,\n",
    "                action,\n",
    "                reward,\n",
    "                next, \n",
    "                done,\n",
    "            )\n",
    "            for i in range(parr):\n",
    "                agent.store(\n",
    "                    data,\n",
    "                    outputs[\"actions\"][i],\n",
    "                    float(outputs[\"rewards\"][i]),\n",
    "                    next,\n",
    "                    bool(outputs[\"dones\"][i])\n",
    "                )\n",
    "\n",
    "\n",
    "def warmUpEnvironment(environment, strategy, parallelEnvironments, rewardFunction):\n",
    "    \"\"\"\n",
    "    'warm up' primaryEnvironmentironment until there's enough data to calculate CVaR\n",
    "    \"\"\"\n",
    "    for _ in range(TIME_WINDOW):\n",
    "        allocations = np.random.normal(scale=1, size=len(productIds))\n",
    "        allocations = np.insert(allocations, 0, 1)\n",
    "        environment.step(softmax(allocations), False, rewardMethod=rewardFunction)\n",
    "        if strategy in RL_STRATS:\n",
    "            for parallel in parallelEnvironments:\n",
    "                parallel.step(softmax(allocations), False, rewardMethod=rewardFunction)\n",
    "    environment.setIsReady(True)\n",
    "    if strategy in RL_STRATS:\n",
    "        for parallel in parallelEnvironments:\n",
    "            parallel.setIsReady(True)\n",
    "            parallel.TD3 = strategy == \"TD3\"\n",
    "\n",
    "def trainingLoop(riskAversion=0, lstmOutputSize=512, rewardFunction=\"CVaR\", freq=int(TRAINING_PERIODS / 25), parr=0, lr=3e-4):\n",
    "    for repeat in range(REPEATS):\n",
    "        for strategy in STRATEGIES:\n",
    "            if repeat > 0 and strategy not in (RL_STRATS + [\"RANDOM\"]):\n",
    "                continue\n",
    "\n",
    "            for episode in range(EXPERIMENTS):\n",
    "                start = episode * TRAINING_PERIODS + (0 if episode == 0 else -TIME_WINDOW)\n",
    "                featureExtractor = LstmFeatureExtractor(TIME_WINDOW, NUMBER_OF_FEATURES, 128, lstmOutputSize)\n",
    "                agent = generateAgent(strategy, lstmOutputSize, riskAversion, lr)\n",
    "                primaryEnvironment, parallelEnvironments = initializeEnvironments(start, parr, rewardFunction, riskAversion, strategy)\n",
    "                primaryEnvironment.reset()\n",
    "                done, doNothing = False, False\n",
    "\n",
    "                while not done:\n",
    "                    if not primaryEnvironment.getIsReady():\n",
    "                        warmUpEnvironment(primaryEnvironment, strategy, parallelEnvironments, rewardFunction)\n",
    "                        continue\n",
    "\n",
    "                    readyToStartTrading = (primaryEnvironment.timeStep) / TRAINING_PERIODS >= 2 / 3\n",
    "                    observation, outputs = None, None\n",
    "\n",
    "                    if strategy in RL_STRATS:\n",
    "                        data = primaryEnvironment.getData()\n",
    "                        observation = featureExtractor.forward(torch.tensor(data, dtype=torch.float32).unsqueeze(0))\n",
    "                        if strategy == \"PPOLSTM\":\n",
    "                            outputs = {\n",
    "                                \"actions\": torch.zeros(parr, agent.actions_n),\n",
    "                                \"probabilities\": torch.zeros(parr, agent.actions_n),\n",
    "                                \"valuations\": torch.zeros(parr, 1),\n",
    "                                \"rewards\": torch.zeros(parr, 1),\n",
    "                                \"dones\": torch.zeros(parr, 1)\n",
    "                            }\n",
    "                            for i in range(parr):\n",
    "                                act, prob, val = agent.select_action(observation)\n",
    "                                outputs[\"actions\"][i] = act\n",
    "                                outputs[\"probabilities\"][i] = prob\n",
    "                                outputs[\"valuations\"][i] = val\n",
    "                        else:\n",
    "                            outputs = {\n",
    "                                \"nextstates\" : torch.zeros(parr, agent.state_n),\n",
    "                                \"actions\" : torch.zeros(parr, agent.actions_n),\n",
    "                                \"rewards\" : torch.zeros(parr, 1),\n",
    "                                \"dones\" : torch.zeros(parr, 1)\n",
    "                            }\n",
    "                            for i in range(parr):\n",
    "                                act = agent.select_action(observation)\n",
    "                                outputs[\"actions\"][i] = act # noise added to action so its fine\n",
    "                        allCashAction = np.array([1] + [0 for _ in productIds]) if doNothing else None\n",
    "\n",
    "                    probabilities, valuation = None, None\n",
    "                    if strategy == \"RANDOM\":\n",
    "                        action = np.random.normal(0, 1, len(productIds) + 1)\n",
    "\n",
    "                    elif strategy in NON_RL_COMPARISON_STRATEGIES:\n",
    "                        action = NON_RL_COMPARISON_STRATEGIES.get(strategy)\n",
    "                    else: \n",
    "                        if strategy == \"PPOLSTM\":\n",
    "                            action, probabilities, valuation = agent.select_action(observation)\n",
    "                        elif strategy == \"TD3\":\n",
    "                            action = agent.select_action(observation) \n",
    "                            \n",
    "                    if not doNothing:\n",
    "                        primaryEnvironment.traded += 1\n",
    "\n",
    "                    finalAction = (\n",
    "                        allCashAction if doNothing else ([0] + action if strategy in NON_RL_COMPARISON_STRATEGIES else softmax(action))\n",
    "                    )\n",
    "                    next, reward, done, _, info = primaryEnvironment.step(finalAction, readyToStartTrading, rewardFunction)\n",
    "                    \n",
    "                    if strategy in RL_STRATS:\n",
    "                        for i in range(parr):\n",
    "                            nexts, rew, do, _, _ = parallelEnvironments[i].step(finalAction, readyToStartTrading, rewardFunction)\n",
    "                            outputs[\"nexts\"][i] = nexts\n",
    "                            outputs[\"rewards\"][i] = rew\n",
    "                            outputs[\"dones\"][i] = int(do)\n",
    "                        if not doNothing:\n",
    "                            storeExperiences(agent, data, outputs, reward, done, strategy, parr, action, probabilities, valuation, next)\n",
    "                            doNothing = info[\"turbulence_breached\"]\n",
    "                        if (primaryEnvironment.timeStep % freq) == 0:\n",
    "                            agent.train(featureExtractor)\n",
    "\n",
    "                    if done:\n",
    "                        dataString = generateConfigLabel(strategy, agent, episode, rewardFunction, freq, parr, lr)\n",
    "                        averagePerformance[dataString].append(primaryEnvironment.PORTFOLIO_VALUES)\n",
    "                        metrics = primaryEnvironment.getMetrics()\n",
    "                        allResults[dataString].append(metrics)\n",
    "                        # table = [metrics.keys()]\n",
    "                        # table.append(metrics.values())\n",
    "                        # tabulate_neatly(table, headers=\"firstrow\", title=f\"{dataString}\")\n",
    "                        # if strategy not in NON_RL_COMPARISON_STRATEGIES.keys() and strategy != \"RANDOM\":\n",
    "                            #nice but take up way too much space...\n",
    "                            # printConfiguration(agent, freq)\n",
    "                            # plotAllocations([0] + action if strategy in NON_RL_COMPARISON_STRATEGIES.keys() else softmax(action), \"Final Allocations\")\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Performance ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bluem\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "if not CRYPTO:\n",
    "    result = np.array_split(times, STARTS, axis=0)[1:]\n",
    "    timeScale = [dates for dates in result]\n",
    "\n",
    "def plotPerformance(test):\n",
    "    for experiment in range(EXPERIMENTS):\n",
    "        plt.figure(figsize=(12,6))\n",
    "        relevantPeriods = int(2/3 * TRAINING_PERIODS) + 2\n",
    "        name = f\"Experiment_{experiment + 1}_\" \n",
    "        portfolioFolder = f\"portfolios/Test-{test}/\"+ datetime.now().strftime(\"%Y-%m-%d\") + \"/\"\n",
    "        plotsFolder = f\"plots/Test-{test}/\"+ datetime.now().strftime(\"%Y-%m-%d\") + \"/\"\n",
    "        if not os.path.exists(portfolioFolder):\n",
    "            os.makedirs(portfolioFolder)\n",
    "        if not os.path.exists(plotsFolder):\n",
    "            os.makedirs(plotsFolder)\n",
    "        for k, v in averagePerformance.items():\n",
    "            if test.lower() in k.lower() or \"RANDOM\" in k: # i wrote this at 12am forgive me\n",
    "                shouldBeSkipped = False\n",
    "                for value in list(NON_RL_COMPARISON_STRATEGIES.keys())[:-1]:\n",
    "                    if value in k:\n",
    "                        shouldBeSkipped = True # only need to compare with buy and hold for now\n",
    "                if shouldBeSkipped:\n",
    "                    continue\n",
    "                v = np.array(v)\n",
    "                v = np.mean(v, axis=0)[relevantPeriods:]\n",
    "                if f\"Experiment {experiment + 1}\" in k:\n",
    "                    l = k.split(\"|\")[0]\n",
    "                    array = np.insert(v, 0, START_CASH)\n",
    "                    # labels = timeScale[experiment][-15:]           \n",
    "                    # labelIndices = range(0, len(labels), 1)  \n",
    "                    # plt.xticks(labelIndices, rotation=45)\n",
    "                    plt.plot(array, label=l) ## too tired\n",
    "                    np.savetxt(f\"{portfolioFolder}{name}{l}.txt\", array, fmt='%f')\n",
    "        plt.title(f\"Returns over Time - Experiment {experiment + 1}. Testing: {test}\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Mean Returns\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"{plotsFolder}{name}\")\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabulate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulateResults():\n",
    "    for k, v in allResults.items():\n",
    "        table = [list(v[0].keys()) + [\"Standard Deviation\"]] \n",
    "        meanReturns, meanMER, meanPB, meanAPPT, meanSR, timeSteps = 0, 0, 0, 0, 0, 0\n",
    "        deviations = []\n",
    "        for resultSet in v:\n",
    "            meanReturns += resultSet[\"Cumulative \\nReturn (%)\"]\n",
    "            deviations.append(resultSet[\"Cumulative \\nReturn (%)\"])\n",
    "            meanMER += resultSet[\"Maximum Earning \\nRate (%)\"]\n",
    "            meanPB += resultSet[\"Maximum \\nPullback (%)\"]\n",
    "            meanAPPT += (resultSet[\"Average Profitability \\nper Trade\"] if type(resultSet[\"Average Profitability \\nper Trade\"]) == float else 0)\n",
    "            meanSR += resultSet[\"Sharpe Ratio\"]\n",
    "            timeSteps += resultSet[\"Total Timesteps\"]\n",
    "        array = [meanReturns, meanMER, meanPB, meanAPPT, meanSR, timeSteps, np.std(deviations)]\n",
    "        array = [i/len(v) for i in array]\n",
    "        table.append(array)\n",
    "        tabulate_neatly(table, headers=\"firstrow\", title=f\"MEAN RESULTS FOR: \" + k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TESTING RISK AVERSION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Risk Aversion-0.25 | Strategy-PPOLSTM | Experiment 1</h3>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">      Cumulative \n",
       "Return (%)</th><th style=\"text-align: right;\">      Maximum Earning \n",
       "Rate (%)</th><th style=\"text-align: right;\">        Maximum \n",
       "Pullback (%)</th><th style=\"text-align: right;\">        Average Profitability \n",
       "per Trade</th><th style=\"text-align: right;\">  Sharpe Ratio</th><th style=\"text-align: right;\">  Total Timesteps</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">42.99</td><td style=\"text-align: right;\">53.75</td><td style=\"text-align: right;\">43.6369</td><td style=\"text-align: right;\">1174.55</td><td style=\"text-align: right;\">        0.1087</td><td style=\"text-align: right;\">             1101</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Risk Aversion-0.25 | Strategy-PPOLSTM | Experiment 2</h3>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">      Cumulative \n",
       "Return (%)</th><th style=\"text-align: right;\">     Maximum Earning \n",
       "Rate (%)</th><th style=\"text-align: right;\">        Maximum \n",
       "Pullback (%)</th><th style=\"text-align: right;\">         Average Profitability \n",
       "per Trade</th><th style=\"text-align: right;\">  Sharpe Ratio</th><th style=\"text-align: right;\">  Total Timesteps</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">-4.66</td><td style=\"text-align: right;\">8.03</td><td style=\"text-align: right;\">49.9948</td><td style=\"text-align: right;\">-127.358</td><td style=\"text-align: right;\">       -0.0118</td><td style=\"text-align: right;\">             1101</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Strategy-RANDOM |  | Experiment 1</h3>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">      Cumulative \n",
       "Return (%)</th><th style=\"text-align: right;\">      Maximum Earning \n",
       "Rate (%)</th><th style=\"text-align: right;\">        Maximum \n",
       "Pullback (%)</th><th style=\"text-align: right;\">        Average Profitability \n",
       "per Trade</th><th style=\"text-align: right;\">  Sharpe Ratio</th><th style=\"text-align: right;\">  Total Timesteps</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">25.73</td><td style=\"text-align: right;\">32.03</td><td style=\"text-align: right;\">34.6353</td><td style=\"text-align: right;\">702.942</td><td style=\"text-align: right;\">        0.0674</td><td style=\"text-align: right;\">             1101</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Strategy-RANDOM |  | Experiment 2</h3>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">      Cumulative \n",
       "Return (%)</th><th style=\"text-align: right;\">      Maximum Earning \n",
       "Rate (%)</th><th style=\"text-align: right;\">        Maximum \n",
       "Pullback (%)</th><th style=\"text-align: right;\">        Average Profitability \n",
       "per Trade</th><th style=\"text-align: right;\">  Sharpe Ratio</th><th style=\"text-align: right;\">  Total Timesteps</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">20.64</td><td style=\"text-align: right;\">24.09</td><td style=\"text-align: right;\">44.1161</td><td style=\"text-align: right;\">563.936</td><td style=\"text-align: right;\">        0.0452</td><td style=\"text-align: right;\">             1101</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"str\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 45\u001b[0m\n\u001b[0;32m     41\u001b[0m     tabulateResults()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Run the tests\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[43mrunTests\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 37\u001b[0m, in \u001b[0;36mrunTests\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     36\u001b[0m TESTING[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m plotPerformance(key)\n\u001b[0;32m     39\u001b[0m TESTING[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 29\u001b[0m, in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTESTING \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtestType\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m testLoops \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRISK AVERSION\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: [\n\u001b[0;32m      7\u001b[0m         trainingLoop(riskAversion\u001b[38;5;241m=\u001b[39mrisk) \u001b[38;5;28;01mfor\u001b[39;00m risk \u001b[38;5;129;01min\u001b[39;00m AGENT_RISK_AVERSIONS\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     ],\n\u001b[0;32m     27\u001b[0m }\n\u001b[1;32m---> 29\u001b[0m \u001b[43mtestLoops\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtestType\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 7\u001b[0m, in \u001b[0;36mtest.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m active:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTESTING \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtestType\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     testLoops \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRISK AVERSION\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: [\n\u001b[1;32m----> 7\u001b[0m             \u001b[43mtrainingLoop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mriskAversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrisk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m risk \u001b[38;5;129;01min\u001b[39;00m AGENT_RISK_AVERSIONS\n\u001b[0;32m      8\u001b[0m         ],\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM OUTPUT SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: [\n\u001b[0;32m     10\u001b[0m             trainingLoop(lstmOutputSize\u001b[38;5;241m=\u001b[39msize) \u001b[38;5;28;01mfor\u001b[39;00m size \u001b[38;5;129;01min\u001b[39;00m LSTMOUTPUTSIZES\n\u001b[0;32m     11\u001b[0m         ],\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREWARD FUNCTION\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: [\n\u001b[0;32m     13\u001b[0m             trainingLoop(\n\u001b[0;32m     14\u001b[0m                 riskAversion\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCVaR\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m), rewardFunction\u001b[38;5;241m=\u001b[39mr\n\u001b[0;32m     15\u001b[0m             )\n\u001b[0;32m     16\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m REWARD_FUNCTIONS\n\u001b[0;32m     17\u001b[0m         ],\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLEARNING FREQUENCY\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: [\n\u001b[0;32m     19\u001b[0m             trainingLoop(freq\u001b[38;5;241m=\u001b[39mfr) \u001b[38;5;28;01mfor\u001b[39;00m fr \u001b[38;5;129;01min\u001b[39;00m LEARNING_FREQUENCIES\n\u001b[0;32m     20\u001b[0m         ],\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPARALLEL ENVIRONMENTS\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: [\n\u001b[0;32m     22\u001b[0m             trainingLoop(parr\u001b[38;5;241m=\u001b[39mpar) \u001b[38;5;28;01mfor\u001b[39;00m par \u001b[38;5;129;01min\u001b[39;00m NUMBER_OF_PARALLEL_ENVIRONMENTS\n\u001b[0;32m     23\u001b[0m         ],\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLEARNING RATE\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m: [\n\u001b[0;32m     25\u001b[0m             trainingLoop(lr\u001b[38;5;241m=\u001b[39mlearn) \u001b[38;5;28;01mfor\u001b[39;00m learn \u001b[38;5;129;01min\u001b[39;00m LEARNING_RATES\n\u001b[0;32m     26\u001b[0m         ],\n\u001b[0;32m     27\u001b[0m     }\n\u001b[0;32m     29\u001b[0m     testLoops[testType]()\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 84\u001b[0m, in \u001b[0;36mtrainingLoop\u001b[1;34m(riskAversion, lstmOutputSize, rewardFunction, freq, parr, lr)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m repeat \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(REPEATS):\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m strategy \u001b[38;5;129;01min\u001b[39;00m STRATEGIES:\n\u001b[1;32m---> 84\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m repeat \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m strategy \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[43mRL_STRATS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRANDOM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m]:\n\u001b[0;32m     85\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EXPERIMENTS):\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    for testType, active in TESTING.items():\n",
    "        if active:\n",
    "            print(f\"TESTING {testType.replace('_', ' ').upper()}\")\n",
    "            testLoops = {\n",
    "                \"RISK AVERSION\": lambda: [\n",
    "                    trainingLoop(riskAversion=risk) for risk in AGENT_RISK_AVERSIONS\n",
    "                ],\n",
    "                \"LSTM OUTPUT SIZE\": lambda: [\n",
    "                    trainingLoop(lstmOutputSize=size) for size in LSTMOUTPUTSIZES\n",
    "                ],\n",
    "                \"REWARD FUNCTION\": lambda: [\n",
    "                    trainingLoop(\n",
    "                        riskAversion=(0.25 if r == \"CVaR\" else 0), rewardFunction=r\n",
    "                    )\n",
    "                    for r in REWARD_FUNCTIONS\n",
    "                ],\n",
    "                \"LEARNING FREQUENCY\": lambda: [\n",
    "                    trainingLoop(freq=fr) for fr in LEARNING_FREQUENCIES\n",
    "                ],\n",
    "                \"PARALLEL ENVIRONMENTS\": lambda: [\n",
    "                    trainingLoop(parr=par) for par in NUMBER_OF_PARALLEL_ENVIRONMENTS\n",
    "                ],\n",
    "                \"LEARNING RATE\": lambda: [\n",
    "                    trainingLoop(lr=learn) for learn in LEARNING_RATES\n",
    "                ],\n",
    "            }\n",
    "            \n",
    "            testLoops[testType]()\n",
    "            break \n",
    "\n",
    "\n",
    "def runTests():\n",
    "    for key in TESTING.keys():\n",
    "        print(\"=\" * 50)\n",
    "        TESTING[key] = True\n",
    "        test()\n",
    "        plotPerformance(key)\n",
    "        TESTING[key] = False\n",
    "        print(\"=\" * 50)\n",
    "    tabulateResults()\n",
    "\n",
    "\n",
    "# Run the tests\n",
    "runTests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Models (if any) Evaluated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMEMBER TO VARY BUT REPEAT SEEDS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
